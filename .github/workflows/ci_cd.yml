name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run daily at 2 AM UTC to update model
    - cron: '0 2 * * *'
  workflow_dispatch:  # Allow manual trigger

env:
  PYTHON_VERSION: '3.9'

jobs:
  # Job 1: Lint and Test
  lint-and-test:
    name: Lint and Test
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest black flake8 pytest-cov
    
    - name: Run Black formatter check
      run: black --check *.py || true
    
    - name: Run Flake8 linter
      run: flake8 *.py --max-line-length=120 --ignore=E501,W503 || true
    
    - name: Run tests
      run: |
        pytest tests/ --cov=. --cov-report=xml || echo "No tests found"
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        files: ./coverage.xml
      continue-on-error: true

  # Job 2: Data Pipeline
  data-pipeline:
    name: Data Ingestion & Processing
    runs-on: ubuntu-latest
    needs: lint-and-test
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run data ingestion
      run: |
        echo "Fetching data from CoinGecko..."
        python data_ingestion.py --days 30
      timeout-minutes: 5
      continue-on-error: false
    
    - name: Validate ingested data
      run: |
        python -c "
        import pandas as pd
        df = pd.read_csv('crypto_prices.csv')
        assert len(df) > 100, 'Insufficient data'
        assert 'price' in df.columns, 'Missing price column'
        print(f'âœ“ Validated {len(df)} records')
        "
    
    - name: Run data processing
      run: |
        echo "Processing data..."
        python data_processing.py --freq 6H
      timeout-minutes: 3
    
    - name: Upload processed data
      uses: actions/upload-artifact@v3
      with:
        name: processed-data
        path: |
          crypto_prices.csv
          processed_prices.csv
        retention-days: 7

  # Job 3: Model Training
  model-training:
    name: Train Forecasting Model
    runs-on: ubuntu-latest
    needs: data-pipeline
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Download processed data
      uses: actions/download-artifact@v3
      with:
        name: processed-data
    
    - name: Train ARIMA model
      run: |
        echo "Training model..."
        python model_training.py --type arima
      timeout-minutes: 10
    
    - name: Validate trained model
      run: |
        python -c "
        import pickle
        import json
        with open('arima_model.pkl', 'rb') as f:
            model = pickle.load(f)
        print('âœ“ Model loaded successfully')
        
        with open('model_metadata.json', 'r') as f:
            metadata = json.load(f)
        print(f'âœ“ Model metrics: {metadata.get(\"metrics\", {})}')
        "
    
    - name: Upload model artifacts
      uses: actions/upload-artifact@v3
      with:
        name: trained-model
        path: |
          arima_model.pkl
          model_metadata.json
        retention-days: 30

  # Job 4: API Testing
  api-testing:
    name: Test API Service
    runs-on: ubuntu-latest
    needs: model-training
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Download artifacts
      uses: actions/download-artifact@v3
      with:
        name: processed-data
    
    - name: Download model
      uses: actions/download-artifact@v3
      with:
        name: trained-model
    
    - name: Start API service
      run: |
        uvicorn api_service:app --host 127.0.0.1 --port 8000 &
        API_PID=$!
        echo "API_PID=$API_PID" >> $GITHUB_ENV
        sleep 10
    
    - name: Test health endpoint
      run: |
        response=$(curl -s http://127.0.0.1:8000/health)
        echo "Health check response: $response"
        echo "$response" | grep -q "healthy"
    
    - name: Test predict endpoint
      run: |
        response=$(curl -s http://127.0.0.1:8000/predict)
        echo "Prediction response: $response"
        echo "$response" | grep -q "predictions"
        
        # Extract and validate prediction
        prediction=$(echo "$response" | python -c "import sys, json; print(json.load(sys.stdin)['predictions'][0])")
        echo "Next price prediction: \$$prediction"
        
        # Validate prediction is reasonable (between $10k and $200k)
        python -c "
        pred = float('$prediction')
        assert 10000 < pred < 200000, f'Prediction {pred} out of reasonable range'
        print('âœ“ Prediction validation passed')
        "
    
    - name: Test model info endpoint
      run: |
        curl -s http://127.0.0.1:8000/model/info | python -m json.tool
    
    - name: Stop API service
      if: always()
      run: |
        if [ ! -z "${{ env.API_PID }}" ]; then
          kill ${{ env.API_PID }} || true
        fi

  # Job 5: Docker Build
  docker-build:
    name: Build Docker Image
    runs-on: ubuntu-latest
    needs: api-testing
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Download artifacts
      uses: actions/download-artifact@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Login to Docker Hub
      uses: docker/login-action@v2
      with:
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}
      continue-on-error: true
    
    - name: Build Docker image
      run: |
        docker build -t crypto-prediction-api:latest .
        docker tag crypto-prediction-api:latest crypto-prediction-api:${{ github.sha }}
    
    - name: Test Docker image
      run: |
        docker run -d -p 8001:8000 --name test-api crypto-prediction-api:latest
        sleep 10
        curl http://localhost:8001/health
        docker stop test-api
        docker rm test-api
    
    - name: Push to Docker Hub
      if: success() && github.event_name == 'push'
      run: |
        docker push crypto-prediction-api:latest
        docker push crypto-prediction-api:${{ github.sha }}
      continue-on-error: true

  # Job 6: Deployment (placeholder)
  deploy:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: docker-build
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    environment:
      name: production
      url: https://your-api-url.com
    
    steps:
    - name: Deploy notification
      run: |
        echo "ðŸš€ Deploying to production..."
        echo "Model version: ${{ github.sha }}"
        # Add your deployment commands here
        # Examples:
        # - Deploy to AWS ECS/Fargate
        # - Deploy to Google Cloud Run
        # - Deploy to Heroku
        # - Update Kubernetes deployment

  # Job 7: Notification
  notify:
    name: Send Notifications
    runs-on: ubuntu-latest
    needs: [data-pipeline, model-training, api-testing]
    if: always()
    
    steps:
    - name: Send success notification
      if: ${{ needs.model-training.result == 'success' }}
      run: |
        echo "âœ“ Pipeline completed successfully"
        # Add Slack/Discord/Email notification here
    
    - name: Send failure notification
      if: ${{ needs.model-training.result == 'failure' }}
      run: |
        echo "âœ— Pipeline failed"
        # Add failure notification here